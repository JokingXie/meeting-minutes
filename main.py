import gradio as gr
import os
import dotenv
from pydub import AudioSegment

from distinguish_speaker import clip_audio, distinguish_speaker
from add_punctuation import add_punctuation
from separate_document import separate_document
from transcribe_audio import transcribe_audio, format_transcription_to_text
from analyze_transcript import analyze_transcript

# åˆå§‹åŒ–å¤„ç†æ¨¡å—


def process_audio(raw_audio_path):
    """
    å¤„ç†ä¼ å…¥çš„éŸ³é¢‘ï¼š
        1. ç»Ÿä¸€è½¬æ¢ä¸º .wav æ ¼å¼
        2. è°ƒç”¨ distinguish_speaker.py ç”Ÿæˆè¯´è¯äººæ—¥å¿—
        3. è°ƒç”¨ transcribe_audio.py ç”Ÿæˆè½¬è¯‘ç»“æœ
        4. å¯¹è½¬è¯‘ç»“æœè¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆé¢„è§ˆã€è½¬è¯‘åŸæ–‡ã€.wav éŸ³é¢‘è·¯å¾„

    :param raw_audio_path: ä¼ å…¥çš„éŸ³é¢‘è·¯å¾„
    :return: preview, transcription, processed_audio_path
    """
    if not raw_audio_path:
        raise gr.Error("è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
    
    # å¦‚æœä¸æ˜¯ .wav æ ¼å¼ï¼Œåˆ™è¿›è¡Œè½¬æ¢
    file_name, file_ext = os.path.splitext(raw_audio_path)
    processed_audio_path = raw_audio_path
    
    if file_ext.lower() != ".wav":
        wav_path = f"{file_name}.wav"
        print(f"Converting {raw_audio_path} to {wav_path}...")
        try:
            sound = AudioSegment.from_file(raw_audio_path)
            # å¯¹äº pydubï¼Œå¯ä»¥è®¾ç½®é‡‡æ ·ç‡å’Œé€šé“æ•°ä»¥ç¬¦åˆæ¨¡å‹è¦æ±‚ï¼Œè¿™é‡Œæš‚æ—¶åªè½¬æ¢æ ¼å¼
            sound.export(wav_path, format="wav")
            processed_audio_path = wav_path
        except Exception as e:
            raise gr.Error(f"éŸ³é¢‘æ–‡ä»¶è½¬æ¢å¤±è´¥: {e}")
            
    # 1. ç”Ÿæˆè¯´è¯äººæ—¥å¿—
    raw_diarization = distinguish_speaker(processed_audio_path)
    
    # 2. ç”Ÿæˆè½¬è¯‘ç»“æœ
    transcription_result = transcribe_audio(processed_audio_path, raw_diarization)

    # 3. ç”Ÿæˆé¢„è§ˆå’Œè½¬è¯‘åŸæ–‡
    k = int(os.getenv("TRANSCRIPTION_PREVIEW_WORDS", "100"))  # é¢„è§ˆçš„å­—ç¬¦æ•°ï¼Œé»˜è®¤100
    speaker_texts = {}
    for _, _, speaker, text in transcription_result.get("result", []):
        if speaker not in speaker_texts:
            speaker_texts[speaker] = ""
        speaker_texts[speaker] += text
    
    preview_lines = []
    # æŒ‰ speaker åç§°æ’åºï¼Œç¡®ä¿é¢„è§ˆè¾“å‡ºé¡ºåºä¸€è‡´
    for speaker in sorted(speaker_texts.keys()):
        preview_lines.append(f"{speaker}ï¼š")
        preview_lines.append(speaker_texts[speaker][:k] + ("..." if len(speaker_texts[speaker]) > k else ""))
        preview_lines.append("")
    
    preview = "\n".join(preview_lines)

    transcript_text = format_transcription_to_text(transcription_result)

    return preview, transcript_text, processed_audio_path

def generate_report(meeting_time, meeting_place, transcript, speakers):
    """
    æ ¹æ®è¡¥å……ä¿¡æ¯+ä¼šè®®è½¬è¯‘ç”Ÿæˆé€šç”¨ã€å¤§çº²å½¢å¼çš„æŠ¥å‘Šã€‚

    :param meeting_time: ä¼šè®®æ—¶é—´
    :param meeting_place: ä¼šè®®åœ°ç‚¹
    :param transcript: ä¼šè®®è½¬è¯‘å†…å®¹
    :param speakers: è¯´è¯äººé¡ºåºä¿¡æ¯
    :return general_result, concise_result, "general_report.md", "concise_report.md" ï¼ˆ.mdæŠ¥å‘Šä¸‹è½½è·¯å¾„ï¼‰
    """
    if not speakers:
        raise gr.Error("è¯·è¾“å…¥è¯´è¯äººä¿¡æ¯")
    if not meeting_time:
        raise gr.Error("è¯·è¾“å…¥ä¼šè®®æ—¶é—´")
    
    # ä¿å­˜è½¬å½•æ–‡ä»¶
    with open("meeting_transcript.txt", "w", encoding="utf-8") as f:
        f.write(transcript)
    
    # ç”ŸæˆåŒ…å«ä¼šè®®ä¿¡æ¯çš„æç¤ºè¯
    prompt_content = (
        f"<ä¼šè®®æ—¶é—´>{meeting_time}</ä¼šè®®æ—¶é—´>\n"
        f"<ä¼šè®®åœ°ç‚¹>{meeting_place}</ä¼šè®®åœ°ç‚¹>\n"
        f"<ä¸ä¼šäººå‘˜>{speakers}</ä¸ä¼šäººå‘˜>\n"
        f"<ä¼šè®®è®°å½•>{transcript}</ä¼šè®®è®°å½•>"
    )
    
    with open("user_prompt.txt", "w", encoding="utf-8") as f:
        f.write(prompt_content)
    
    # æ‰§è¡Œåˆ†æ
    analysis_result = analyze_transcript(
        user_prompt_path="user_prompt.txt"
    )

    general_result = analysis_result.get("general_report", "")
    concise_result = analysis_result.get("concise_report", "")

    with open("general_report.md", "w", encoding="utf-8") as f:
        f.write(general_result)

    with open("concise_report.md", "w", encoding="utf-8") as f:
        f.write(concise_result)
    
    return general_result, concise_result, "general_report.md", "concise_report.md"

# Gradioç•Œé¢æ„å»º
with gr.Blocks(title="ä¼šè®®çºªè¦ç”Ÿæˆç³»ç»Ÿ") as demo:
    gr.Markdown("## ğŸ™ï¸ ä¼šè®®æ™ºèƒ½åˆ†æç³»ç»Ÿ")
    
    # çŠ¶æ€å˜é‡
    transcript_state = gr.State()
    audio_state = gr.State()
    
    with gr.Tab("ä¼šè®®å¤„ç†"):
        with gr.Row(equal_height=True):
            with gr.Column(scale=1):  # è®¾ç½®è¾ƒå°çš„æ¯”ä¾‹
                audio_input = gr.Audio(scale=1, type="filepath", label="ä¸Šä¼ ä¼šè®®å½•éŸ³")

                gr.Markdown("""
                <div style="color: #ff8c00; background-color: #fff4e6; padding: 10px; border-radius: 5px; margin-bottom: 10px; height: 100%;">
                è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–è¿›è¡Œå½•éŸ³ï¼ŒéŸ³é¢‘æ–‡ä»¶æ”¯æŒä¸»æµçš„.WAV, .MP3, .M4A, .WMA, .AAC, .FLACç­‰æ ¼å¼ã€‚
                ä¸Šä¼ éŸ³é¢‘å®Œæˆåï¼Œè¯·ç‚¹å‡»"å¼€å§‹å¤„ç†"æŒ‰é’®ï¼Œç­‰å¾…å†…å®¹é¢„è§ˆç”Ÿæˆå®Œæˆã€‚
                </div>
                """)  

                transcribe_audio_btn = gr.Button(scale=3, value="å¼€å§‹å¤„ç†", variant="primary")

                gr.Markdown("""
                <div style="color: #ff8c00; background-color: #fff4e6; padding: 10px; border-radius: 5px; margin-bottom: 10px; height: 100%;">
                è¯·ç­‰å¾…å†…å®¹é¢„è§ˆçš„ç”Ÿæˆï¼Œè¡¥å……ç›¸åº”çš„ä¼šè®®ä¿¡æ¯åï¼Œç‚¹å‡»"ç”ŸæˆæŠ¥å‘Š"æŒ‰é’®ç”Ÿæˆå¯¹åº”çš„æŠ¥å‘Šã€‚
                </div>
                """)  
                
            with gr.Column(scale=3):
                preview_output = gr.Textbox(label="å†…å®¹é¢„è§ˆ", lines=28, min_width=600) 

            with gr.Column(scale=3):
                transcript_output = gr.Textbox(
                    label="è½¬è¯‘åŸæ–‡", 
                    lines=28, 
                    min_width=600,
                    interactive=True
                )
            
        with gr.Row(equal_height=True):

            with gr.Column(scale=1):            
                generate_report_btn = gr.Button(scale=1, value="ç”ŸæˆæŠ¥å‘Š", variant="primary")

            with gr.Column(scale=2):
                speaker_input = gr.Textbox(scale=2, label="å‘è¨€äººä¿¡æ¯", placeholder="è¯·æŒ‰åºè¾“å…¥å¯¹åº”çš„å‘è¨€äººä¿¡æ¯")
            with gr.Column(scale=2):
                meeting_time = gr.Textbox(scale=2, label="ä¼šè®®æ—¶é—´", placeholder="å¦‚ï¼š2024å¹´9æœˆ19æ—¥ æ˜ŸæœŸå›› 10:00")
            with gr.Column(scale=2):
                meeting_place = gr.Textbox(scale=2, label="ä¼šè®®åœ°ç‚¹", placeholder="ä¾‹å¦‚ï¼šä¼šè®®å®¤302")

        with gr.Tab("é€šç”¨æŠ¥å‘Š"):
            general_report_output = gr.Markdown(label="é€šç”¨æŠ¥å‘Š")
            general_download = gr.File(label="ä¸‹è½½æŠ¥å‘Š")

        with gr.Tab("å¤§çº²æŠ¥å‘Š"):
            concise_report_output = gr.Markdown(label="å¤§çº²æŠ¥å‘Š")
            concise_download = gr.File(label="ä¸‹è½½æŠ¥å‘Š")
        

    # äº‹ä»¶ç»‘å®š
    transcribe_audio_btn.click(
        process_audio,
        inputs=audio_input,
        outputs=[preview_output, transcript_output, audio_state]
    )
    
    generate_report_btn.click(
        generate_report,
        inputs=[meeting_time, meeting_place, transcript_output, speaker_input],
        outputs=[general_report_output, concise_report_output, general_download, concise_download]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)